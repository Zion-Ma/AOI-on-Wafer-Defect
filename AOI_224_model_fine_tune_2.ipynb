{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AOI_224_model_fine_tune_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnA1dm8z-rcF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed2gD78M-sPO"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/Programming(II)/Lesson13_AOIDemo/aoi.zip'\n",
        "drive_path = '/content/drive/MyDrive/aoi/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoUfkk_yAIKd"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/aoi/train_images.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjI9wE1B_UH7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOSe3_r5_c77"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import os\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "      # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeI6Dhu__vTE"
      },
      "source": [
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "# load file as CSV\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import numpy\n",
        "import numpy as np\n",
        "filename = '/content/drive/MyDrive/aoi/train.csv'\n",
        "mapping1_csv = read_csv(filename,encoding=\"Big5\")\n",
        "filename = '/content/drive/MyDrive/aoi/test.csv'\n",
        "mapping2_csv = read_csv(filename,encoding=\"Big5\")\n",
        "mapping1_csv = mapping1_csv.values.tolist()\n",
        "mapping2_csv = mapping2_csv.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hjoBl5BAf8r"
      },
      "source": [
        "print(type(mapping1_csv))\n",
        "print(len(mapping1_csv))\n",
        "print(mapping1_csv[0])\n",
        "print(mapping2_csv[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H29t7nGwAmr7"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "\n",
        "def load_dataset(directory,mapping_csv):\n",
        "    X, y = list(), list()\n",
        "    data = []\n",
        "    labels = []\n",
        "    i=0\n",
        "    # loop over the image paths\n",
        "    for imagePath, label in mapping_csv:\n",
        "        image = Image.open(directory + imagePath)\n",
        "        image = image.convert('RGB')\n",
        "        image = image.resize((224,224))\n",
        "        image = asarray(image)\n",
        "        data.append(image)\n",
        "        labels.append(label)\n",
        "    # convert the data and labels to NumPy arrays while scaling the pixel\n",
        "    # perform one-hot encoding on the labels\n",
        "    from keras import utils as np_utils\n",
        "    lb = LabelBinarizer()\n",
        "    labels = lb.fit_transform(labels)\n",
        "    X.extend(data)\n",
        "    y.extend(labels)\n",
        "    return asarray(X), asarray(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlYFcTMWAu4b"
      },
      "source": [
        "trainX, trainy = load_dataset('train_images/',mapping1_csv)\n",
        "print(trainX.shape, trainy.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om7JusyABGGi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Tp0IXdURzo"
      },
      "source": [
        "# input_tensor = Input(shape=(224, 224, 3))\n",
        "# model = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "# model_1 = Sequential()\n",
        "# for layer in model.layers:\n",
        "#   print(layer)\n",
        "#   model_1.add(layer)\n",
        "# model_1.add(Flatten())\n",
        "# model_1.add(Dense(1000, activation = \"softmax\"))\n",
        "# model_1.add(Dense(6, activation = \"softmax\"))\n",
        "# model_1.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16FHUzpyiHWF"
      },
      "source": [
        "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a model integrated with VGG16 pretrained layers\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training. Defaults to 'RMSProp'\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze.\n",
        "                If set to 0, all pretrained layers will freeze during training\n",
        "    \"\"\"\n",
        "    \n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    conv_base = VGG16(include_top=False,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
        "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
        "    top_model = conv_base.output\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    top_model = Dense(4096, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    top_model = Dense(1072, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yGEP68CiQkb"
      },
      "source": [
        "model=create_model((224,224,3),6,optimizer='rmsprop',fine_tune=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjHlwm-b1A_M"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abi1rh5N6aFt"
      },
      "source": [
        "model.fit(trainX, trainy , batch_size=20, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enXNSA5a6uPn"
      },
      "source": [
        "model.evaluate(trainX,trainy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqAeBBmDFjdJ"
      },
      "source": [
        "model.save('model_VGG16_fine_tune_5.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxaJ4Eic7n0R"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/aoi/test_images.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AmNlNy3BeNv"
      },
      "source": [
        "def load_dataset(directory,mapping_csv):\n",
        "    X= list()\n",
        "    data = []\n",
        "    i=0\n",
        "    # loop over the image paths\n",
        "    for imagePath, label in mapping_csv:\n",
        "        image = Image.open(directory + imagePath)\n",
        "        image = image.convert('RGB')\n",
        "        image = image.resize((224,224))\n",
        "        image = asarray(image)\n",
        "        data.append(image)\n",
        "    # convert the data and labels to NumPy arrays while scaling the pixel\n",
        "    # perform one-hot encoding on the labels\n",
        "    from keras import utils as np_utils\n",
        "    X.extend(data)\n",
        "    return asarray(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZMLSZmfAyn7"
      },
      "source": [
        "testX= load_dataset('test_images/',mapping2_csv)\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMSjSZ32CHGN"
      },
      "source": [
        "y_pred=model.predict(testX)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ax4Qmw4_knZ"
      },
      "source": [
        "test_result=[]\n",
        "for pred in y_pred:\n",
        "  test_result.append(np.argmax(pred))\n",
        "test_result=np.array(test_result).reshape(-1,1)\n",
        "test_result.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxmdjFOHq-_j"
      },
      "source": [
        "df_test=pd.read_csv('/content/drive/MyDrive/aoi/test.csv')\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61oMP34AsOGw"
      },
      "source": [
        "df_test.Label=test_result\n",
        "df_test.to_csv('final_10.csv',index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR29V8-ZSG-0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}