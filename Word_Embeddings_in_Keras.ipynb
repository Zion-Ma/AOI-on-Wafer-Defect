{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPwNnV9wZs+DAQKfIUB+W6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zion-Ma/AOI-on-Wafer-Defect/blob/main/Word_Embeddings_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0N4cc7uvZryF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3340dbfa-538a-441a-ecc6-ddf9ad8e9800"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
        "\n",
        "\n",
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "# encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "# print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "\n",
        "max_length = 4\n",
        "# print(encoded_docs)\n",
        "# padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "# print(padded_docs)\n",
        "\n",
        "def encoding(docs):\n",
        "\tencoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "\t# print(encoded_docs)\n",
        "\tpadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "\t# print(padded_docs)\n",
        "\treturn padded_docs\n",
        "\n",
        "padded_docs = encoding(docs)\n",
        "\t\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojtTjuHbZu9q",
        "outputId": "5a6449cb-4923-47da-cf82-08b78acb9dfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              400       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Accuracy: 89.999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Could have done better\"\n",
        "s = one_hot(s, vocab_size)\n",
        "s = pad_sequences([s], maxlen=max_length, padding='post')\n",
        "w = model.predict(s)[0,0]\n",
        "if w < 0.5:\n",
        "\tprint(1-w, 'NEGATIVE')\n",
        "else:\n",
        "  print(w, 'POSITIVE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gXg0hMfbH7o",
        "outputId": "70af26c7-4847-4bda-9bcc-4b88f3d0be30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "0.6145768463611603 NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# from keras.preprocessing.sequence import pad_sequences\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.layers import Flatten\n",
        "# from keras.layers import Embedding\n",
        "\n",
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
        "\n",
        "\n",
        "# prepare tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(docs)\n",
        "print(t.word_index)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(docs)\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = max(len(item) for item in encoded_docs)\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "\n",
        "\n",
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/2022_NLP/GloVe/glove.6B.100d.txt', mode='rt', encoding='utf-8')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "5_tRbJxigqTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807c7441-bc51-4f32-897c-1ee0a24477d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'work': 1, 'done': 2, 'good': 3, 'effort': 4, 'poor': 5, 'well': 6, 'great': 7, 'nice': 8, 'excellent': 9, 'weak': 10, 'not': 11, 'could': 12, 'have': 13, 'better': 14}\n",
            "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n",
            "[[ 6  2  0  0]\n",
            " [ 3  1  0  0]\n",
            " [ 7  4  0  0]\n",
            " [ 8  1  0  0]\n",
            " [ 9  0  0  0]\n",
            " [10  0  0  0]\n",
            " [ 5  4  0  0]\n",
            " [11  3  0  0]\n",
            " [ 5  1  0  0]\n",
            " [12 13  2 14]]\n",
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
        "model.add(e)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=1)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQp_jBGHy428",
        "outputId": "c249e1e4-5de6-42dc-bcaa-30bbebbb5989"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_30 (Embedding)    (None, 4, 100)            1500      \n",
            "                                                                 \n",
            " flatten_28 (Flatten)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901\n",
            "Trainable params: 401\n",
            "Non-trainable params: 1,500\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 611ms/step - loss: 0.6966 - acc: 0.4000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6820 - acc: 0.5000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6680 - acc: 0.5000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6547 - acc: 0.6000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6419 - acc: 0.7000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6298 - acc: 0.7000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6182 - acc: 0.7000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6070 - acc: 0.9000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5963 - acc: 0.9000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5859 - acc: 0.9000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5759 - acc: 0.9000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5662 - acc: 0.9000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5568 - acc: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5476 - acc: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5387 - acc: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5301 - acc: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5216 - acc: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5134 - acc: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5054 - acc: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4977 - acc: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4901 - acc: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4827 - acc: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4755 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4685 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4617 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4550 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4485 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4422 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4360 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4299 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4240 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4182 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4125 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4070 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4015 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3961 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3909 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3857 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.3807 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3757 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3708 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3660 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3613 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.3567 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3522 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3477 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3434 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3391 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3349 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3307 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6f9c25add0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Functional API calling\n",
        "\n",
        "# from keras.layers import Input\n",
        "# from keras import Model\n",
        "\n",
        "# input = Input(shape = (max_length,))\n",
        "# x = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)(input)\n",
        "# x = Flatten()(x)\n",
        "# output = Dense(1, activation='sigmoid')(x)\n",
        "# model_try = Model(inputs = input, outputs = output, name = \"model_try\")\n",
        "# model_try.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# model_try.summary()\n",
        "\n",
        "# model_try.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# # evaluate the model\n",
        "# loss, accuracy = model_try.evaluate(padded_docs, labels, verbose=0)\n",
        "# print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaZlsM_A2h4X",
        "outputId": "3d44d1a6-3833-48b6-d5b6-214ea081f742"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_try\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_22 (InputLayer)       [(None, 4)]               0         \n",
            "                                                                 \n",
            " embedding_28 (Embedding)    (None, 4, 100)            1500      \n",
            "                                                                 \n",
            " flatten_26 (Flatten)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,901\n",
            "Trainable params: 401\n",
            "Non-trainable params: 1,500\n",
            "_________________________________________________________________\n",
            "Accuracy: 100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_encoding(s):\n",
        "  encoded_s = t.texts_to_sequences([s])\n",
        "  # pad documents to a max length of 4 words\n",
        "  padded_s = pad_sequences(encoded_s, maxlen=max_length, padding='post')\n",
        "  return padded_s\n",
        "\n",
        "for s in docs:\n",
        "  # integer encode the documents\n",
        "  padded_s = token_encoding(s)\n",
        "  y_pred = model.predict(padded_s, verbose = 0)[0,0]\n",
        "  print(s, end = \"\\t\")\n",
        "  if y_pred < 0.5:\n",
        "    print(1-y_pred, 'NEGATIVE')\n",
        "  else:\n",
        "    print(y_pred, 'POSITIVE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKKTwQUV6rIj",
        "outputId": "c0d1cad5-33b3-4799-ed36-22ac629ca8d2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well done!\t0.73316574 POSITIVE\n",
            "Good work\t0.7211444 POSITIVE\n",
            "Great effort\t0.67933047 POSITIVE\n",
            "nice work\t0.742616 POSITIVE\n",
            "Excellent!\t0.7419425 POSITIVE\n",
            "Weak\t0.7231066226959229 NEGATIVE\n",
            "Poor effort!\t0.6894666850566864 NEGATIVE\n",
            "not good\t0.6862711608409882 NEGATIVE\n",
            "poor work\t0.596337229013443 NEGATIVE\n",
            "Could have done better.\t0.9444424845278263 NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"weak commitment\"\n",
        "padded_s = token_encoding(s)\n",
        "y_pred = model.predict(padded_s, verbose = 0)[0,0]\n",
        "print(s, end = \"\\t\")\n",
        "if y_pred < 0.5:\n",
        "  print(1-y_pred, 'NEGATIVE')\n",
        "else:\n",
        "  print(y_pred, 'POSITIVE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvwcU3rcFY8T",
        "outputId": "bd16b673-059b-41f2-e566-ad9ab9ced0ba"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weak commitment\t0.7231066226959229 NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/drive/MyDrive/dis_hw.ipynb /content/"
      ],
      "metadata": {
        "id": "4SmglCmIHlzR"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3Y9K8O4Iblv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}